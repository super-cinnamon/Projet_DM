{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and datafraem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547619</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.715820</td>\n",
       "      <td>Sales</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.814978</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.185735</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.613136</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915934</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>Other</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545855</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.928610</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.793478</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444950</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394188</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>Medical</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Attrition  BusinessTravel  DailyRate              Department  \\\n",
       "0  0.547619          1             1.0   0.715820                   Sales   \n",
       "1  0.814978          0             0.5   0.185735  Research & Development   \n",
       "2  0.613136          1             1.0   0.915934  Research & Development   \n",
       "3  0.545855          0             0.5   0.928610  Research & Development   \n",
       "4  0.444950          0             1.0   0.394188  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EnvironmentSatisfaction  \\\n",
       "0          0.000000   0.250000  Life Sciences                 0.333333   \n",
       "1          0.275862   0.157895  Life Sciences                 0.727273   \n",
       "2          0.068966   0.380435          Other                 1.000000   \n",
       "3          0.103448   0.793478  Life Sciences                 1.000000   \n",
       "4          0.068966   0.173913        Medical                 0.181818   \n",
       "\n",
       "   Gender  ...  PercentSalaryHike  RelationshipSatisfaction  StockOptionLevel  \\\n",
       "0     0.0  ...               0.00                      0.00               0.0   \n",
       "1     1.0  ...               0.92                      1.00               0.5   \n",
       "2     1.0  ...               0.60                      0.50               0.0   \n",
       "3     0.0  ...               0.44                      0.75               0.0   \n",
       "4     1.0  ...               0.48                      1.00               0.5   \n",
       "\n",
       "  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0             0.000                    0.0            0.00            0.15   \n",
       "1             0.025                    0.5            0.75            0.25   \n",
       "2             0.025                    0.5            0.75            0.00   \n",
       "3             0.025                    0.5            0.75            0.20   \n",
       "4             0.025                    0.5            0.75            0.05   \n",
       "\n",
       "   YearsInCurrentRole  YearsSinceLastPromotion YearsWithCurrManager  \n",
       "0            0.222222                 0.000000             0.344828  \n",
       "1            0.388889                 0.066667             0.482759  \n",
       "2            0.000000                 0.000000             0.000000  \n",
       "3            0.388889                 0.200000             0.000000  \n",
       "4            0.111111                 0.133333             0.137931  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBscan from scratch\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('new_dataset.csv')\n",
    "\n",
    "# Print the first 5 rows of the data    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBSCAN: \n",
    "    def __init__(self, eps, min_pts, data):\n",
    "        self.eps = eps\n",
    "        self.min_pts = min_pts\n",
    "        self.data = data\n",
    "        self.clusters = []\n",
    "        self.noise = []\n",
    "        self.core_pts = []\n",
    "        self.visited = []\n",
    "        self.clustered = []\n",
    "        self.cluster_num = 0\n",
    "        self.clustered_pts = []\n",
    "        \n",
    "    def _distance(self, p1, p2):\n",
    "        result = 0\n",
    "        for i in range(len(p1)):\n",
    "            if(type(p1[i]) == str or type(p2[i]) == str):\n",
    "                if(p1[i] != p2[i]):\n",
    "                    result += 1\n",
    "            else : result += (p1[i] - p2[i]) ** 2\n",
    "        return math.sqrt(result)\n",
    "        #return math.sqrt(sum([(a - b) ** 2 for a, b in zip(p1, p2)]))\n",
    "    \n",
    "    def _region_query(self, point):\n",
    "        neighbors = []\n",
    "        for i in range(len(self.data)):\n",
    "            if self._distance(point, self.data[i]) < self.eps:\n",
    "                neighbors.append(i)\n",
    "        return neighbors\n",
    "    \n",
    "    def _expand_cluster(self, point, neighbors):\n",
    "        self.clusters[self.cluster_num].append(point)\n",
    "        self.clustered.append(point)\n",
    "        self.visited.append(point)\n",
    "        for i in neighbors:\n",
    "            if i not in self.visited:\n",
    "                self.visited.append(i)\n",
    "                new_neighbors = self._region_query(self.data[i])\n",
    "                if len(new_neighbors) >= self.min_pts:\n",
    "                    neighbors += new_neighbors\n",
    "            if i not in self.clustered:\n",
    "                self.clusters[self.cluster_num].append(i)\n",
    "                self.clustered.append(i)\n",
    "                \n",
    "    def fit(self):\n",
    "        for i in range(len(self.data)):\n",
    "            if i not in self.visited:\n",
    "                self.visited.append(i)\n",
    "                neighbors = self._region_query(self.data[i])\n",
    "                if len(neighbors) < self.min_pts:\n",
    "                    self.noise.append(i)\n",
    "                else:\n",
    "                    self.clusters.append([])\n",
    "                    self._expand_cluster(i, neighbors)\n",
    "                    self.cluster_num += 1\n",
    "                    \n",
    "    def get_clusters(self):\n",
    "        return self.clusters\n",
    "    \n",
    "    def get_noise(self):\n",
    "        return self.noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Attrition'].values\n",
    "df = df.drop(['Attrition'], axis=1)\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=2.135, min_pts=1, data=X)\n",
    "dbscan.fit()\n",
    "clusters = dbscan.get_clusters()\n",
    "noise = dbscan.get_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbscan.get_clusters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  70,\n",
       "  115,\n",
       "  132,\n",
       "  168,\n",
       "  174,\n",
       "  215,\n",
       "  318,\n",
       "  320,\n",
       "  327,\n",
       "  376,\n",
       "  397,\n",
       "  450,\n",
       "  525,\n",
       "  566,\n",
       "  665,\n",
       "  719,\n",
       "  747,\n",
       "  829,\n",
       "  834,\n",
       "  849,\n",
       "  897,\n",
       "  947,\n",
       "  1011,\n",
       "  1121,\n",
       "  1255,\n",
       "  1270,\n",
       "  18,\n",
       "  22,\n",
       "  29,\n",
       "  43,\n",
       "  48,\n",
       "  63,\n",
       "  66,\n",
       "  75,\n",
       "  82,\n",
       "  89,\n",
       "  96,\n",
       "  117,\n",
       "  131,\n",
       "  136,\n",
       "  137,\n",
       "  138,\n",
       "  143,\n",
       "  154,\n",
       "  165,\n",
       "  167,\n",
       "  179,\n",
       "  212,\n",
       "  216,\n",
       "  218,\n",
       "  219,\n",
       "  227,\n",
       "  228,\n",
       "  230,\n",
       "  238,\n",
       "  261,\n",
       "  282,\n",
       "  328,\n",
       "  332,\n",
       "  347,\n",
       "  355,\n",
       "  358,\n",
       "  366,\n",
       "  370,\n",
       "  374,\n",
       "  393,\n",
       "  401,\n",
       "  402,\n",
       "  410,\n",
       "  431,\n",
       "  442,\n",
       "  445,\n",
       "  446,\n",
       "  448,\n",
       "  461,\n",
       "  462,\n",
       "  464,\n",
       "  490,\n",
       "  493,\n",
       "  502,\n",
       "  520,\n",
       "  527,\n",
       "  529,\n",
       "  531,\n",
       "  536,\n",
       "  548,\n",
       "  563,\n",
       "  569,\n",
       "  573,\n",
       "  574,\n",
       "  580,\n",
       "  583,\n",
       "  591,\n",
       "  596,\n",
       "  603,\n",
       "  606,\n",
       "  608,\n",
       "  624,\n",
       "  641,\n",
       "  646,\n",
       "  659,\n",
       "  662,\n",
       "  670,\n",
       "  672,\n",
       "  679,\n",
       "  685,\n",
       "  694,\n",
       "  695,\n",
       "  703,\n",
       "  705,\n",
       "  706,\n",
       "  712,\n",
       "  754,\n",
       "  771,\n",
       "  794,\n",
       "  802,\n",
       "  805,\n",
       "  811,\n",
       "  839,\n",
       "  850,\n",
       "  866,\n",
       "  884,\n",
       "  885,\n",
       "  915,\n",
       "  943,\n",
       "  963,\n",
       "  964,\n",
       "  974,\n",
       "  980,\n",
       "  990,\n",
       "  993,\n",
       "  1012,\n",
       "  1016,\n",
       "  1051,\n",
       "  1057,\n",
       "  1070,\n",
       "  1079,\n",
       "  1103,\n",
       "  1120,\n",
       "  1132,\n",
       "  1144,\n",
       "  1172,\n",
       "  1191,\n",
       "  1194,\n",
       "  1220,\n",
       "  1237,\n",
       "  1249,\n",
       "  1253,\n",
       "  1254,\n",
       "  1285,\n",
       "  1319,\n",
       "  1333,\n",
       "  1350,\n",
       "  1366,\n",
       "  1454,\n",
       "  5,\n",
       "  8,\n",
       "  19,\n",
       "  21,\n",
       "  23,\n",
       "  24,\n",
       "  27,\n",
       "  30,\n",
       "  32,\n",
       "  33,\n",
       "  37,\n",
       "  39,\n",
       "  42,\n",
       "  46,\n",
       "  47,\n",
       "  56,\n",
       "  67,\n",
       "  72,\n",
       "  76,\n",
       "  78,\n",
       "  81,\n",
       "  85,\n",
       "  88,\n",
       "  91,\n",
       "  94,\n",
       "  97,\n",
       "  98,\n",
       "  101,\n",
       "  107,\n",
       "  113,\n",
       "  121,\n",
       "  124,\n",
       "  133,\n",
       "  141,\n",
       "  144,\n",
       "  146,\n",
       "  151,\n",
       "  158,\n",
       "  169,\n",
       "  176,\n",
       "  177,\n",
       "  198,\n",
       "  210,\n",
       "  211,\n",
       "  217,\n",
       "  220,\n",
       "  223,\n",
       "  241,\n",
       "  252,\n",
       "  254,\n",
       "  258,\n",
       "  264,\n",
       "  265,\n",
       "  273,\n",
       "  274,\n",
       "  281,\n",
       "  285,\n",
       "  289,\n",
       "  293,\n",
       "  296,\n",
       "  297,\n",
       "  300,\n",
       "  301,\n",
       "  303,\n",
       "  306,\n",
       "  321,\n",
       "  329,\n",
       "  335,\n",
       "  337,\n",
       "  339,\n",
       "  348,\n",
       "  349,\n",
       "  356,\n",
       "  359,\n",
       "  367,\n",
       "  371,\n",
       "  372,\n",
       "  378,\n",
       "  379,\n",
       "  381,\n",
       "  384,\n",
       "  389,\n",
       "  403,\n",
       "  422,\n",
       "  429,\n",
       "  430,\n",
       "  432,\n",
       "  437,\n",
       "  439,\n",
       "  443,\n",
       "  447,\n",
       "  452,\n",
       "  456,\n",
       "  480,\n",
       "  482,\n",
       "  486,\n",
       "  495,\n",
       "  496,\n",
       "  499,\n",
       "  507,\n",
       "  508,\n",
       "  517,\n",
       "  518,\n",
       "  522,\n",
       "  528,\n",
       "  532,\n",
       "  534,\n",
       "  546,\n",
       "  556,\n",
       "  564,\n",
       "  567,\n",
       "  576,\n",
       "  598,\n",
       "  611,\n",
       "  619,\n",
       "  621,\n",
       "  622,\n",
       "  625,\n",
       "  638,\n",
       "  675,\n",
       "  680,\n",
       "  684,\n",
       "  687,\n",
       "  693,\n",
       "  698,\n",
       "  699,\n",
       "  700,\n",
       "  702,\n",
       "  704,\n",
       "  710,\n",
       "  727,\n",
       "  735,\n",
       "  736,\n",
       "  741,\n",
       "  742,\n",
       "  755,\n",
       "  757,\n",
       "  764,\n",
       "  768,\n",
       "  775,\n",
       "  787,\n",
       "  790,\n",
       "  791,\n",
       "  795,\n",
       "  801,\n",
       "  806,\n",
       "  814,\n",
       "  818,\n",
       "  819,\n",
       "  820,\n",
       "  821,\n",
       "  822,\n",
       "  835,\n",
       "  838,\n",
       "  844,\n",
       "  846,\n",
       "  853,\n",
       "  856,\n",
       "  857,\n",
       "  865,\n",
       "  869,\n",
       "  870,\n",
       "  873,\n",
       "  874,\n",
       "  876,\n",
       "  879,\n",
       "  894,\n",
       "  898,\n",
       "  901,\n",
       "  902,\n",
       "  904,\n",
       "  911,\n",
       "  912,\n",
       "  933,\n",
       "  935,\n",
       "  939,\n",
       "  946,\n",
       "  949,\n",
       "  951,\n",
       "  952,\n",
       "  956,\n",
       "  959,\n",
       "  961,\n",
       "  969,\n",
       "  975,\n",
       "  984,\n",
       "  987,\n",
       "  991,\n",
       "  1002,\n",
       "  1006,\n",
       "  1018,\n",
       "  1021,\n",
       "  1026,\n",
       "  1030,\n",
       "  1031,\n",
       "  1033,\n",
       "  1038,\n",
       "  1041,\n",
       "  1042,\n",
       "  1046,\n",
       "  1048,\n",
       "  1049,\n",
       "  1059,\n",
       "  1063,\n",
       "  1064,\n",
       "  1074,\n",
       "  1075,\n",
       "  1082,\n",
       "  1083,\n",
       "  1084,\n",
       "  1091,\n",
       "  1094,\n",
       "  1102,\n",
       "  1105,\n",
       "  1106,\n",
       "  1108,\n",
       "  1109,\n",
       "  1119,\n",
       "  1124,\n",
       "  1135,\n",
       "  1152,\n",
       "  1158,\n",
       "  1178,\n",
       "  1180,\n",
       "  1186,\n",
       "  1189,\n",
       "  1195,\n",
       "  1196,\n",
       "  1197,\n",
       "  1205,\n",
       "  1213,\n",
       "  1216,\n",
       "  1218,\n",
       "  1231,\n",
       "  1235,\n",
       "  1241,\n",
       "  1247,\n",
       "  1251,\n",
       "  1257,\n",
       "  1269,\n",
       "  1271,\n",
       "  1276,\n",
       "  1281,\n",
       "  1284,\n",
       "  1292,\n",
       "  1294,\n",
       "  1309,\n",
       "  1316,\n",
       "  1325,\n",
       "  1326,\n",
       "  1338,\n",
       "  1342,\n",
       "  1343,\n",
       "  1363,\n",
       "  1364,\n",
       "  1384,\n",
       "  1385,\n",
       "  1391,\n",
       "  1393,\n",
       "  1394,\n",
       "  1396,\n",
       "  1407,\n",
       "  1423,\n",
       "  1448,\n",
       "  3,\n",
       "  11,\n",
       "  38,\n",
       "  52,\n",
       "  54,\n",
       "  57,\n",
       "  74,\n",
       "  92,\n",
       "  122,\n",
       "  157,\n",
       "  175,\n",
       "  192,\n",
       "  205,\n",
       "  235,\n",
       "  246,\n",
       "  263,\n",
       "  277,\n",
       "  295,\n",
       "  307,\n",
       "  319,\n",
       "  331,\n",
       "  343,\n",
       "  352,\n",
       "  354,\n",
       "  361,\n",
       "  368,\n",
       "  377,\n",
       "  380,\n",
       "  433,\n",
       "  438,\n",
       "  444,\n",
       "  453,\n",
       "  472,\n",
       "  479,\n",
       "  481,\n",
       "  500,\n",
       "  504,\n",
       "  505,\n",
       "  533,\n",
       "  589,\n",
       "  597,\n",
       "  600,\n",
       "  607,\n",
       "  612,\n",
       "  614,\n",
       "  634,\n",
       "  635,\n",
       "  643,\n",
       "  644,\n",
       "  645,\n",
       "  648,\n",
       "  651,\n",
       "  666,\n",
       "  667,\n",
       "  676,\n",
       "  683,\n",
       "  720,\n",
       "  730,\n",
       "  750,\n",
       "  751,\n",
       "  760,\n",
       "  763,\n",
       "  830,\n",
       "  836,\n",
       "  842,\n",
       "  845,\n",
       "  854,\n",
       "  859,\n",
       "  872,\n",
       "  888,\n",
       "  909,\n",
       "  917,\n",
       "  929,\n",
       "  945,\n",
       "  981,\n",
       "  986,\n",
       "  996,\n",
       "  997,\n",
       "  1019,\n",
       "  1025,\n",
       "  1058,\n",
       "  1061,\n",
       "  1067,\n",
       "  1080,\n",
       "  1095,\n",
       "  1100,\n",
       "  1101,\n",
       "  1110,\n",
       "  1126,\n",
       "  1145,\n",
       "  1147,\n",
       "  1164,\n",
       "  1167,\n",
       "  1198,\n",
       "  1204,\n",
       "  1214,\n",
       "  1229,\n",
       "  1274,\n",
       "  1314,\n",
       "  1340,\n",
       "  1349,\n",
       "  1356,\n",
       "  1358,\n",
       "  1359,\n",
       "  1369,\n",
       "  1374,\n",
       "  1392,\n",
       "  44,\n",
       "  103,\n",
       "  109,\n",
       "  114,\n",
       "  118,\n",
       "  140,\n",
       "  159,\n",
       "  236,\n",
       "  315,\n",
       "  322,\n",
       "  338,\n",
       "  417,\n",
       "  487,\n",
       "  540,\n",
       "  542,\n",
       "  549,\n",
       "  649,\n",
       "  661,\n",
       "  739,\n",
       "  743,\n",
       "  788,\n",
       "  926,\n",
       "  960,\n",
       "  983,\n",
       "  1014,\n",
       "  1050,\n",
       "  1118,\n",
       "  1321,\n",
       "  1451,\n",
       "  65,\n",
       "  206,\n",
       "  363,\n",
       "  387,\n",
       "  494,\n",
       "  521,\n",
       "  560,\n",
       "  577,\n",
       "  674,\n",
       "  778,\n",
       "  807,\n",
       "  932,\n",
       "  950,\n",
       "  988,\n",
       "  1013,\n",
       "  1188,\n",
       "  1200,\n",
       "  1236,\n",
       "  1267,\n",
       "  1304,\n",
       "  1433,\n",
       "  14,\n",
       "  50,\n",
       "  102,\n",
       "  112,\n",
       "  127,\n",
       "  142,\n",
       "  182,\n",
       "  214,\n",
       "  233,\n",
       "  239,\n",
       "  253,\n",
       "  290,\n",
       "  316,\n",
       "  357,\n",
       "  369,\n",
       "  408,\n",
       "  414,\n",
       "  457,\n",
       "  553,\n",
       "  602,\n",
       "  688,\n",
       "  711,\n",
       "  731,\n",
       "  758,\n",
       "  776,\n",
       "  815,\n",
       "  881,\n",
       "  913,\n",
       "  1081,\n",
       "  1123,\n",
       "  1153,\n",
       "  1317,\n",
       "  2,\n",
       "  6,\n",
       "  16,\n",
       "  26,\n",
       "  34,\n",
       "  41,\n",
       "  51,\n",
       "  55,\n",
       "  69,\n",
       "  71,\n",
       "  106,\n",
       "  111,\n",
       "  125,\n",
       "  130,\n",
       "  149,\n",
       "  170,\n",
       "  181,\n",
       "  185,\n",
       "  191,\n",
       "  195,\n",
       "  229,\n",
       "  248,\n",
       "  278,\n",
       "  291,\n",
       "  294,\n",
       "  309,\n",
       "  312,\n",
       "  323,\n",
       "  342,\n",
       "  346,\n",
       "  382,\n",
       "  383,\n",
       "  388,\n",
       "  396,\n",
       "  409,\n",
       "  421,\n",
       "  449,\n",
       "  463,\n",
       "  501,\n",
       "  512,\n",
       "  513,\n",
       "  514,\n",
       "  524,\n",
       "  530,\n",
       "  547,\n",
       "  554,\n",
       "  559,\n",
       "  562,\n",
       "  565,\n",
       "  578,\n",
       "  579,\n",
       "  587,\n",
       "  594,\n",
       "  620,\n",
       "  626,\n",
       "  632,\n",
       "  636,\n",
       "  639,\n",
       "  656,\n",
       "  658,\n",
       "  663,\n",
       "  668,\n",
       "  673,\n",
       "  709,\n",
       "  715,\n",
       "  726,\n",
       "  732,\n",
       "  737,\n",
       "  753,\n",
       "  762,\n",
       "  767,\n",
       "  777,\n",
       "  779,\n",
       "  783,\n",
       "  798,\n",
       "  808,\n",
       "  823,\n",
       "  827,\n",
       "  833,\n",
       "  860,\n",
       "  871,\n",
       "  886,\n",
       "  889,\n",
       "  891,\n",
       "  892,\n",
       "  893,\n",
       "  895,\n",
       "  896,\n",
       "  906,\n",
       "  910,\n",
       "  921,\n",
       "  924,\n",
       "  925,\n",
       "  927,\n",
       "  931,\n",
       "  934,\n",
       "  940,\n",
       "  971,\n",
       "  972,\n",
       "  982,\n",
       "  989,\n",
       "  995,\n",
       "  1001,\n",
       "  1007,\n",
       "  1023,\n",
       "  1027,\n",
       "  1028,\n",
       "  1032,\n",
       "  1060,\n",
       "  1062,\n",
       "  1065,\n",
       "  1069,\n",
       "  1085,\n",
       "  1122,\n",
       "  1137,\n",
       "  1142,\n",
       "  1163,\n",
       "  1168,\n",
       "  1169,\n",
       "  1170,\n",
       "  1171,\n",
       "  1179,\n",
       "  1192,\n",
       "  1201,\n",
       "  1212,\n",
       "  1215,\n",
       "  1238,\n",
       "  1244,\n",
       "  1248,\n",
       "  1250,\n",
       "  1258,\n",
       "  1273,\n",
       "  1279,\n",
       "  1293,\n",
       "  1307,\n",
       "  1315,\n",
       "  1332,\n",
       "  1334,\n",
       "  1339,\n",
       "  1375,\n",
       "  1435,\n",
       "  36,\n",
       "  416,\n",
       "  652,\n",
       "  664,\n",
       "  903,\n",
       "  1087,\n",
       "  180,\n",
       "  234,\n",
       "  280,\n",
       "  364,\n",
       "  391,\n",
       "  406,\n",
       "  471,\n",
       "  669,\n",
       "  744,\n",
       "  970,\n",
       "  973,\n",
       "  994,\n",
       "  1009,\n",
       "  1047,\n",
       "  1071,\n",
       "  1161,\n",
       "  1162,\n",
       "  1297,\n",
       "  1337,\n",
       "  1371,\n",
       "  87,\n",
       "  134,\n",
       "  188,\n",
       "  213,\n",
       "  249,\n",
       "  255,\n",
       "  305,\n",
       "  313,\n",
       "  324,\n",
       "  325,\n",
       "  330,\n",
       "  333,\n",
       "  351,\n",
       "  423,\n",
       "  427,\n",
       "  465,\n",
       "  466,\n",
       "  469,\n",
       "  475,\n",
       "  478,\n",
       "  488,\n",
       "  492,\n",
       "  572,\n",
       "  604,\n",
       "  616,\n",
       "  650,\n",
       "  654,\n",
       "  677,\n",
       "  697,\n",
       "  728,\n",
       "  738,\n",
       "  772,\n",
       "  784,\n",
       "  810,\n",
       "  812,\n",
       "  852,\n",
       "  855,\n",
       "  905,\n",
       "  916,\n",
       "  928,\n",
       "  968,\n",
       "  1072,\n",
       "  1134,\n",
       "  1154,\n",
       "  1223,\n",
       "  1232,\n",
       "  1233,\n",
       "  1243,\n",
       "  1259,\n",
       "  1272,\n",
       "  1286,\n",
       "  1299,\n",
       "  1300,\n",
       "  1305,\n",
       "  1306,\n",
       "  1328,\n",
       "  1346,\n",
       "  1355,\n",
       "  1380,\n",
       "  1410,\n",
       "  1416,\n",
       "  1417,\n",
       "  1431,\n",
       "  1439,\n",
       "  1446,\n",
       "  1453,\n",
       "  341,\n",
       "  400,\n",
       "  631,\n",
       "  1096,\n",
       "  1296,\n",
       "  61,\n",
       "  1308,\n",
       "  1464,\n",
       "  385,\n",
       "  1378,\n",
       "  1395,\n",
       "  49,\n",
       "  633,\n",
       "  682,\n",
       "  1017,\n",
       "  1039,\n",
       "  1053,\n",
       "  196,\n",
       "  1193,\n",
       "  152,\n",
       "  237,\n",
       "  595,\n",
       "  1278,\n",
       "  908,\n",
       "  1295,\n",
       "  171,\n",
       "  1406,\n",
       "  25,\n",
       "  186,\n",
       "  190,\n",
       "  244,\n",
       "  411,\n",
       "  425,\n",
       "  538,\n",
       "  561,\n",
       "  627,\n",
       "  749,\n",
       "  858,\n",
       "  861,\n",
       "  867,\n",
       "  907,\n",
       "  955,\n",
       "  999,\n",
       "  1076,\n",
       "  1111,\n",
       "  1116,\n",
       "  1184,\n",
       "  1275,\n",
       "  1330,\n",
       "  15,\n",
       "  28,\n",
       "  45,\n",
       "  59,\n",
       "  110,\n",
       "  116,\n",
       "  123,\n",
       "  129,\n",
       "  187,\n",
       "  189,\n",
       "  207,\n",
       "  251,\n",
       "  276,\n",
       "  279,\n",
       "  344,\n",
       "  386,\n",
       "  390,\n",
       "  394,\n",
       "  420,\n",
       "  455,\n",
       "  526,\n",
       "  541,\n",
       "  590,\n",
       "  593,\n",
       "  681,\n",
       "  692,\n",
       "  752,\n",
       "  773,\n",
       "  792,\n",
       "  837,\n",
       "  930,\n",
       "  936,\n",
       "  953,\n",
       "  1004,\n",
       "  1008,\n",
       "  1043,\n",
       "  1150,\n",
       "  1157,\n",
       "  1159,\n",
       "  1173,\n",
       "  1177,\n",
       "  1225,\n",
       "  1426,\n",
       "  292,\n",
       "  424,\n",
       "  851,\n",
       "  58,\n",
       "  172,\n",
       "  302,\n",
       "  362,\n",
       "  458,\n",
       "  509,\n",
       "  816,\n",
       "  862,\n",
       "  958,\n",
       "  1211,\n",
       "  545,\n",
       "  1,\n",
       "  7,\n",
       "  10,\n",
       "  12,\n",
       "  13,\n",
       "  68,\n",
       "  73,\n",
       "  84,\n",
       "  90,\n",
       "  99,\n",
       "  104,\n",
       "  120,\n",
       "  147,\n",
       "  148,\n",
       "  155,\n",
       "  156,\n",
       "  166,\n",
       "  197,\n",
       "  200,\n",
       "  224,\n",
       "  242,\n",
       "  247,\n",
       "  250,\n",
       "  259,\n",
       "  260,\n",
       "  262,\n",
       "  267,\n",
       "  269,\n",
       "  287,\n",
       "  299,\n",
       "  311,\n",
       "  317,\n",
       "  345,\n",
       "  365,\n",
       "  373,\n",
       "  375,\n",
       "  399,\n",
       "  404,\n",
       "  412,\n",
       "  419,\n",
       "  434,\n",
       "  441,\n",
       "  483,\n",
       "  498,\n",
       "  503,\n",
       "  506,\n",
       "  511,\n",
       "  515,\n",
       "  519,\n",
       "  537,\n",
       "  543,\n",
       "  558,\n",
       "  ...],\n",
       " [1447]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.get_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dbscan.get_noise())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan.get_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sklearn dbscan\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# X = df.values\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "# clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AGNES:\n",
    "    def __init__(self, n_clusters=2, linkage='average'):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.linkage = linkage\n",
    "        self.labels_ = None\n",
    "        self.cluster_centers_ = None\n",
    "        self.n_leaves = None\n",
    "        self.results = {}\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = np.array([self.string_to_numerical(x) for x in X])\n",
    "        self.n_leaves = X.shape[0]\n",
    "        self.labels_ = np.arange(self.n_leaves)\n",
    "        self.cluster_centers_ = X.copy()\n",
    "        self.results[self.n_leaves+1] = [self.labels_.copy(), self.cluster_centers_.copy()]\n",
    "\n",
    "        # while self.n_leaves >= self.n_clusters:\n",
    "        #     self.merge()\n",
    "\n",
    "        while self.n_leaves >= 1:\n",
    "            self.merge()\n",
    "            self.results[self.n_leaves+1] = [self.labels_.copy(), self.cluster_centers_.copy()]\n",
    "        return self\n",
    "\n",
    "    def merge(self):\n",
    "        dist = self.distance(self.cluster_centers_)\n",
    "        i, j = np.unravel_index(dist.argmin(), dist.shape)\n",
    "        self.cluster_centers_[i] = self._linkage(i, j)\n",
    "        self.cluster_centers_ = np.delete(self.cluster_centers_, j, axis=0)\n",
    "        self.labels_[self.labels_ == j] = i\n",
    "        self.labels_[self.labels_ > j] -= 1\n",
    "        self.n_leaves -= 1\n",
    "    \n",
    "    def string_to_numerical(self,arr):\n",
    "        \"\"\"Convert a string to a numerical value\"\"\"\n",
    "        # Convert the string to a list of ASCII values\n",
    "        new_arr = []\n",
    "        for s in arr:\n",
    "            #print(type(s))\n",
    "            if (type(s) == str):\n",
    "                ascii_values = [ord(c) for c in s]\n",
    "                # Convert the list of ASCII values to a numpy array\n",
    "                ascii_array = np.array(ascii_values)\n",
    "                # Return the sum of the array\n",
    "                new_arr.append(ascii_array.sum())\n",
    "            else: new_arr.append(s)\n",
    "        return np.array(new_arr)\n",
    "\n",
    "    def distance(self, X):\n",
    "        return np.sqrt(-2 * np.dot(X, X.T) + np.sum(X ** 2, axis=1) + np.sum(X ** 2, axis=1)[:, np.newaxis])\n",
    "\n",
    "    def _distance(self, p1, p2):\n",
    "        result = 0\n",
    "        for i in range(len(p1)):\n",
    "            if(type(p1[i]) == str or type(p2[i]) == str):\n",
    "                if(p1[i] != p2[i]):\n",
    "                    result += 1\n",
    "            else : result += (p1[i] - p2[i]) ** 2\n",
    "        return math.sqrt(result)\n",
    "\n",
    "    def distance2(self, X):\n",
    "        distances = []\n",
    "        for i in range(len(X)):\n",
    "            for j in range(len(X)):\n",
    "                distances.append(self._distance(X[i], X[j]))\n",
    "        return np.array(distances).reshape(len(X), len(X))\n",
    "                \n",
    "    \n",
    "\n",
    "    def _linkage(self, i, j):\n",
    "        if self.linkage == 'average':\n",
    "            # linkage = []\n",
    "            # for i in range (len(self.cluster_centers_[i])):\n",
    "            #     if type(self.cluster_centers_[i][i]) == str:\n",
    "            #         if self.cluster_centers_[i][i] != self.cluster_centers_[j][i]:\n",
    "            #             linkage.append(0)\n",
    "            #         else: linkage.append(1)\n",
    "            #     else: linkage.append((self.cluster_centers_[i][i] + self.cluster_centers_[j][i]))\n",
    "            # linkage = np.array(linkage)\n",
    "            # return linkage / 2\n",
    "            return (self.cluster_centers_[i] + self.cluster_centers_[j]) / 2\n",
    "        elif self.linkage == 'single':\n",
    "            return np.minimum(self.cluster_centers_[i], self.cluster_centers_[j])\n",
    "        elif self.linkage == 'complete':\n",
    "            return np.maximum(self.cluster_centers_[i], self.cluster_centers_[j])\n",
    "        else:\n",
    "            raise ValueError('Unknown linkage method: {}'.format(self.linkage))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.labels_\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        self.fit(X)\n",
    "        return self.predict(X)\n",
    "\n",
    "    def get_results(self):\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agnes = AGNES(n_clusters=2, linkage='average')\n",
    "res = agnes.fit_predict(X)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = agnes.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for each in results[2][0]:\n",
    "        print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tn = np.sum((1 - y_true) * (1 - y_pred))\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "def f_score(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# confusion matrix containing true positives, false negatives, false positives and true negatives\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    tn = np.sum((1 - y_true) * (1 - y_pred))\n",
    "    return np.array([[tp, fn], [fp, tn]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8387755102040816\n",
      "precision = nan\n",
      "sensitivity = 0.0\n",
      "specificity = 1.0\n",
      "f_score = nan\n",
      "confusion_matrix = \n",
      "[[   0  237]\n",
      " [   0 1233]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  \n",
      "C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy = {accuracy(Y, res)}\")\n",
    "print(f\"precision = {precision(Y, res)}\")\n",
    "print(f\"sensitivity = {sensitivity(Y, res)}\")\n",
    "print(f\"specificity = {specificity(Y, res)}\")\n",
    "print(f\"f_score = {f_score(Y, res)}\")\n",
    "print(f\"confusion_matrix = \\n{confusion_matrix(Y, res)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_res = {}\n",
    "val = 0\n",
    "for cluster in dbscan.get_clusters():\n",
    "        for i in cluster:\n",
    "                dbscan_res[i] = val\n",
    "        val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order dict by key\n",
    "dbscan_res = {k: dbscan_res[k] for k in sorted(dbscan_res)}\n",
    "dbscan_res = list(dbscan_res.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_res = np.array(dbscan_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.8380952380952381\n",
      "precision = 0.0\n",
      "sensitivity = 0.0\n",
      "specificity = 0.9991889699918897\n",
      "f_score = nan\n",
      "confusion_matrix = \n",
      "[[   0  237]\n",
      " [   1 1232]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YsPC\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy = {accuracy(Y, dbscan_res)}\")\n",
    "print(f\"precision = {precision(Y, dbscan_res)}\")\n",
    "print(f\"sensitivity = {sensitivity(Y, dbscan_res)}\")\n",
    "print(f\"specificity = {specificity(Y, dbscan_res)}\")\n",
    "print(f\"f_score = {f_score(Y, dbscan_res)}\")\n",
    "print(f\"confusion_matrix = \\n{confusion_matrix(Y, dbscan_res)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Sales'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-1eb8969e14ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0magg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maffinity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'average'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0magg_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1052\u001b[0m             \u001b[0mCluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \"\"\"\n\u001b[1;32m-> 1054\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    734\u001b[0m         \u001b[1;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[1;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \"\"\"\n\u001b[1;32m--> 917\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\YsPC\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    747\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Sales'"
     ]
    }
   ],
   "source": [
    "# sklearn agglomerative clustering \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "agg = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='average')\n",
    "agg_res = agg.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in agg_res:\n",
    "        print(each)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef545868ebe32c0c19943cd724395eaefc95151b54bafda088e747bf03113afe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
